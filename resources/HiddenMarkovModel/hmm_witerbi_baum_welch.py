"""
Реализация алгоритмов прямого и обратного проходов (forward и backward) для скрытых марковских моделей (HMM).
В HMM используется вероятностная модель для описания последовательности наблюдаемых событий, которые связаны с латентной
последовательностью скрытых состояний. Эти алгоритмы прямого и обратного проходов используются для вычисления апостериорных
вероятностей состояний в HMM.

Матрица переходных вероятностей (a) и матрица вероятностей эмиссий (b) - это два из основных компонентов,
определяющих структуру скрытой марковской модели (Hidden Markov Model, HMM).

1. **Матрица переходных вероятностей (a)**:
   - Эта матрица определяет вероятности переходов между скрытыми состояниями HMM.
   - В данном случае, есть два скрытых состояния (представленных строками и столбцами матрицы),
   и a[i][j] представляет вероятность перехода из состояния i в состояние j.
   - Начальные значения (0.54, 0.46) и (0.49, 0.51) могут быть определены на основе предварительных знаний о системе,
   которую вы моделируете, или могут быть оценены на основе обучающих данных с использованием методов,
   таких как алгоритмы Expectation-Maximization (EM) или другие статистические методы.

2. **Матрица вероятностей эмиссий (b)**:
   - Эта матрица определяет вероятности наблюдаемых символов или событий при каждом скрытом состоянии.
   - В данном случае, есть два скрытых состояния (представленных строками матрицы), и b[i][j] представляет вероятность
   наблюдения символа (или события) j при скрытом состоянии i.
   - Начальные значения (0.16, 0.26, 0.58) и (0.25, 0.28, 0.47) также могут быть заданы на основе предварительных
   знаний о том, какие наблюдаемые события более вероятны для каждого скрытого состояния,
   или они могут быть оценены из обучающих данных.

Важно отметить, что точные значения этих матриц могут существенно влиять на работу HMM и интерпретацию результатов.
В реальных задачах оценка этих параметров может быть сложной задачей и требовать обширного анализа данных или
использования алгоритмов обучения.

При вычислении алгоритма backward (обратного прохода) в скрытых марковских моделях, обычно не используются
результаты forward (прямого прохода) напрямую. Это связано с тем, что forward и backward - это два независимых процесса
вычисления апостериорных вероятностей состояний и не взаимодействуют напрямую друг с другом.

По сути, обратный проход (backward) служит для вычисления апостериорных вероятностей состояний, начиная с конца
последовательности и двигаясь назад к началу. Он использует те же параметры модели (матрицу переходных вероятностей a
и матрицу вероятностей эмиссий b), но начинает с завершения последовательности и двигается в обратном направлении.

Поэтому backward независимо вычисляет вероятности состояний, и результаты forward не требуются.
Он использует информацию о вероятностях состояний в будущем (после текущего момента времени) из матрицы b и матрицы
переходных вероятностей a для вычисления вероятностей в текущем моменте времени и в прошлом.

Оба forward и backward алгоритмы играют ключевую роль в различных методах анализа и обучения на основе HMM,
таких, как оценка параметров модели, выравнивание последовательностей и декодирование скрытых состояний.
Вместе они позволяют полностью оценить апостериорные вероятности и сделать различные выводы о скрытых состояниях
и последовательностях.

Матрицы alpha и beta, полученные с помощью алгоритмов forward и backward для скрытых марковских моделей (HMM),
используются для вычисления различных вероятностей и для решения различных задач, связанных с моделью.
Вот несколько способов их использования:

1. **Вычисление апостериорных вероятностей состояний**:
   - Суммарные апостериорные вероятности состояний можно вычислить, используя матрицу alpha и beta.
   Это полезно, если вы хотите знать, насколько вероятны разные состояния в каждом моменте времени, основываясь
   на наблюдениях.
   - Апостериорные вероятности состояний в момент времени t вычисляются как произведение соответствующих значений
   alpha и beta и нормализуются.

2. **Выравнивание последовательностей**:
   - Матрицы alpha и beta могут быть использованы для выравнивания последовательностей, если HMM применяется, например,
   в задачах распознавания речи или выравнивания биологических последовательностей (например, выравнивания генов).
   - Выравнивание позволяет определить соответствие между наблюдаемыми данными и скрытыми состояниями, что может быть
   полезно при анализе и интерпретации результатов.

3. **Оценка параметров модели**:
   - Матрицы alpha и beta могут быть использованы для оценки параметров скрытой марковской модели (например, матрицы
   переходных вероятностей и матрицы вероятностей эмиссий), если вы хотите обучить модель на основе имеющихся данных.
   - Максимизация правдоподобия с использованием метода Баума-Велша (Baum-Welch) или EM-алгоритмов может быть выполнена
   на основе alpha и beta, чтобы настроить параметры модели.

4. **Декодирование скрытых состояний**:
   - Матрицы alpha и beta также могут быть использованы для декодирования скрытых состояний в последовательности.
   Например, в распознавании речи, это может помочь определить, какие фонемы или слова присутствуют в аудиозаписи.

Использование alpha и beta зависит от конкретной задачи и контекста модели HMM. Они предоставляют информацию о
вероятностях и связях между скрытыми состояниями и наблюдаемыми данными, что делает их мощным инструментом для
разнообразных приложений.

Алгоритм Витерби и алгоритм Баума-Велша - это два ключевых алгоритма, используемых в контексте скрытых марковских
моделей (HMM). Они имеют сходства и отличия:

**Сходства:**

1. **Использование HMM**: Оба алгоритма используют скрытые марковские модели (HMM) для моделирования
последовательностей данных. HMM являются мощными статистическими инструментами для моделирования последовательных
данных с учетом скрытой структуры.

2. **Цель - оценка параметров**: Как Витерби, так и Баум-Велш направлены на оценку параметров HMM на основе наблюдаемых
данных. Это включает в себя оценку матрицы переходных вероятностей и матрицы вероятностей эмиссий.

3. **Итеративный процесс**: Оба алгоритма включают в себя итеративные процессы. Витерби выполняет итерацию для
нахождения наиболее вероятной последовательности скрытых состояний, а Баум-Велш выполняет итерации для оценки
параметров HMM.

**Отличия:**

1. **Цель исследования**:
   - Витерби: Главная цель алгоритма Витерби - найти наиболее вероятную последовательность скрытых состояний HMM,
   соответствующую наблюдаемой последовательности. Это используется, например, в задачах распознавания речи для
   нахождения наилучшего пути через скрытую структуру HMM.
   - Баум-Велш: Основная цель алгоритма Баума-Велша - настроить параметры HMM (матрицу переходов и матрицу
   вероятностей эмиссий) так, чтобы они максимизировали правдоподобие наблюдаемых данных. Этот алгоритм используется
   в задачах обучения HMM на основе имеющихся данных.

2. **Используемые оценки**:
   - Витерби: Оценивает наиболее вероятную последовательность скрытых состояний, но не обновляет параметры модели.
   - Баум-Велш: Обновляет параметры модели (a и b) на основе данных, но не выдаёт наиболее вероятную
   последовательность состояний.

   Основная задача алгоритма Витерби - это определение наиболее вероятной последовательности скрытых
   состояний (маршрута) в HMM, учитывая модель HMM и последовательность наблюдений.
   Он выполняет это путем нахождения пути с наибольшей вероятностью, который максимизирует совместную
   вероятность наблюдений и скрытых состояний.

    Обучение параметров HMM, таких как матрицы переходов, начальные вероятности и параметры эмиссии,
    выполняется другими алгоритмами, такими как алгоритм Баума-Велша (Baum-Welch algorithm) или методы
    максимального правдоподобия (maximum likelihood estimation). Эти алгоритмы используют размеченные
    данные для оценки параметров модели.

    Таким образом, алгоритм Витерби - это инструмент для применения обученной модели HMM к данным,
    а не для самого обучения модели.

3. **Итерации**:
   - Витерби: Производит одну итерацию для нахождения наиболее вероятной последовательности скрытых состояний.
   - Баум-Велш: Выполняет множество итераций (обычно фиксированное количество) для настройки параметров модели.

4. **Задача**:
   - Витерби: Задача Витерби - это задача декодирования, она ответственна за нахождение наилучшей последовательности
   скрытых состояний, учитывая модель HMM.
   - Баум-Велш: Задача Баума-Велша - это задача обучения, она направлена на обновление параметров модели HMM на
   основе имеющихся данных.

В итоге, Витерби и Баум-Велш - это два алгоритма, которые дополняют друг друга. Витерби помогает выбирать
наилучшие последовательности скрытых состояний для наблюдаемых данных, в то время как Баум-Велш помогает настроить
параметры модели HMM так, чтобы она лучше соответствовала данным.
"""

# Импортируем необходимые библиотеки
import pandas as pd
import numpy as np


# Определяем функцию forward для вычисления апостериорных вероятностей состояний
def forward(V, a, b, initial_distribution):
    # Создаем массив alpha для хранения промежуточных значений апостериорных вероятностей
    alpha = np.zeros((V.shape[0], a.shape[0]))

    # Вычисляем начальные значения alpha для первого наблюдения
    alpha[0, :] = initial_distribution * b[:, V[0]]

    # Проходим по последовательности наблюдений
    for t in range(1, V.shape[0]):
        for j in range(a.shape[0]):
            # Вычисляем апостериорную вероятность для текущего состояния j в момент времени t
            alpha[t, j] = alpha[t - 1].dot(a[:, j]) * b[j, V[t]]

    return alpha


# Определяем функцию backward для обратного прохода
def backward(V, a, b):
    # Создаем массив beta для хранения промежуточных значений апостериорных вероятностей
    beta = np.zeros((V.shape[0], a.shape[0]))

    # Устанавливаем значение beta(T) равным 1 (последний момент времени)
    beta[V.shape[0] - 1] = np.ones((a.shape[0]))

    # Обратный проход по последовательности наблюдений от T-1 до 0
    for t in range(V.shape[0] - 2, -1, -1):
        for j in range(a.shape[0]):
            # Вычисляем апостериорную вероятность для текущего состояния j в момент времени t
            beta[t, j] = (beta[t + 1] * b[:, V[t + 1]]).dot(a[j, :])

    return beta


def viterbi(V, a, b, initial_distribution):
    # Получаем длину последовательности V
    T = V.shape[0]
    # Получаем количество скрытых состояний (меток)
    M = a.shape[0]

    # Создаем матрицу omega для хранения логарифма вероятностей
    omega = np.zeros((T, M))
    # Вычисляем начальные значения omega для первого наблюдения
    omega[0, :] = np.log(initial_distribution * b[:, V[0]])

    # Создаем матрицу prev для отслеживания предыдущих состояний
    prev = np.zeros((T - 1, M))

    # Прямой проход по последовательности
    for t in range(1, T):
        for j in range(M):
            # Вычисляем вероятности для всех возможных предыдущих состояний
            # (логарифмы для избежания численных проблем)
            probability = omega[t - 1] + np.log(a[:, j]) + np.log(b[j, V[t]])

            # Запоминаем индекс самой вероятной предыдущей метки (состояния)
            prev[t - 1, j] = np.argmax(probability)

            # Запоминаем самую вероятную вероятность
            omega[t, j] = np.max(probability)

    # Создаем массив S для хранения последовательности скрытых состояний
    S = np.zeros(T)

    # Находим наиболее вероятное последнее скрытое состояние
    last_state = np.argmax(omega[T - 1, :])

    S[0] = last_state

    # Обратное отслеживание для восстановления последовательности
    backtrack_index = 1
    for i in range(T - 2, -1, -1):
        S[backtrack_index] = prev[i, int(last_state)]
        last_state = prev[i, int(last_state)]
        backtrack_index += 1

    # Переворачиваем последовательность обратно, так как мы обратно отслеживали
    S = np.flip(S, axis=0)

    # Преобразуем числовые значения в фактические скрытые состояния (например, "A" или "B")
    result = []
    for s in S:
        if s == 0:
            result.append("A")
        else:
            result.append("B")

    return result


import numpy as np


def baum_welch(V, a, b, initial_distribution, n_iter=100):
    M = a.shape[0]  # Количество скрытых состояний
    T = len(V)  # Длина наблюдаемой последовательности

    for n in range(n_iter):
        # Прямой проход (forward) для вычисления alpha
        alpha = forward(V, a, b, initial_distribution)

        # Обратный проход (backward) для вычисления beta
        beta = backward(V, a, b)

        # Вычисление xi - вероятностей переходов между скрытыми состояниями
        xi = np.zeros((M, M, T - 1))
        for t in range(T - 1):
            denominator = np.dot(np.dot(alpha[t, :].T, a) * b[:, V[t + 1]].T, beta[t + 1, :])
            for i in range(M):
                numerator = alpha[t, i] * a[i, :] * b[:, V[t + 1]].T * beta[t + 1, :].T
                xi[i, :, t] = numerator / denominator

        # Вычисление gamma - вероятностей нахождения в конкретном скрытом состоянии
        gamma = np.sum(xi, axis=1)

        # Обновление матрицы переходных вероятностей a
        a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))

        # Добавление дополнительного элемента в gamma для последнего момента времени
        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))

        K = b.shape[1]

        # Обновление матрицы вероятностей эмиссий b
        denominator = np.sum(gamma, axis=1)
        for l in range(K):
            b[:, l] = np.sum(gamma[:, V == l], axis=1)

        b = np.divide(b, denominator.reshape((-1, 1)))

    # Возвращаем обновленные матрицы a и b
    return {"a": a, "b": b}


# Загружаем данные из CSV-файла 'data_python.csv' с использованием pandas
data = pd.read_csv('data_python.csv')

# Извлекаем столбец 'Visible' из данных
V = data['Visible'].values


forward_backward_run = False
witerbi_run = False
baum_welch_run = True

if forward_backward_run:
    # Определяем матрицу переходных вероятностей (a) для скрытой марковской модели
    a = np.array(((0.54, 0.46), (0.49, 0.51)))

    # Определяем матрицу вероятностей эмиссий (b) для скрытой марковской модели
    b = np.array(((0.16, 0.26, 0.58), (0.25, 0.28, 0.47)))

    # Задаем начальное распределение состояний (initial_distribution) с равными вероятностями
    initial_distribution = np.array((0.5, 0.5))
    # Вызываем функцию forward для вычисления апостериорных вероятностей с использованием данных V и заданных параметров
    alpha = forward(V, a, b, initial_distribution)

    # Выводим результаты
    print(alpha)

    # Вызываем функцию backward для вычисления апостериорных вероятностей с использованием данных V и заданных параметров
    beta = backward(V, a, b)

    # Выводим результаты
    print(beta)


if witerbi_run:
    # Определяем матрицу переходных вероятностей (a) для скрытой марковской модели
    a = np.ones((2, 2))
    a = a / np.sum(a, axis=1)

    # Определяем матрицу переходных вероятностей (a) для скрытой марковской модели
    b = np.array(((1, 3, 5), (2, 4, 6)))
    b = b / np.sum(b, axis=1).reshape((-1, 1))

    # Определяем матрицу вероятностей эмиссий (b) для скрытой марковской модели
    initial_distribution = np.array((0.5, 0.5))

    a, b = baum_welch(V, a, b, initial_distribution, n_iter=100)

    print(viterbi(V, a, b, initial_distribution))


if baum_welch_run:
    # Определяем матрицу переходных вероятностей (a) для скрытой марковской модели
    a = np.ones((2, 2))
    a = a / np.sum(a, axis=1)

    # Определяем матрицу вероятностей эмиссий (b) для скрытой марковской модели
    b = np.array(((1, 3, 5), (2, 4, 6)))
    b = b / np.sum(b, axis=1).reshape((-1, 1))

    # Задаем начальное распределение состояний (initial_distribution) с равными вероятностями
    initial_distribution = np.array((0.5, 0.5))

    print(baum_welch(V, a, b, initial_distribution, n_iter=100))

